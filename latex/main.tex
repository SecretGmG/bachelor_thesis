\documentclass{article}

%-- My Definitions
\usepackage{mydefs}

%-- Math stuff
\usepackage{mathtools, bbm}
%-- Physics and Chemistry stuff
\usepackage{physics}

\usepackage[version=4]{mhchem}
\usepackage{braket}
\usepackage{siunitx}
\sisetup{
    input-digits = 0123456789\pi,
    separate-uncertainty,
    table-align-uncertainty,
    table-number-alignment = center
}

%to compile Feynman diagrams: uncomment these
%can take a lot of compile time, set the compiler to LuaLaTex
\usepackage[compat=1.1.0]{tikz-feynman}
\usepackage{tikz}

%-- Computer science stuff
\usepackage{algorithm, algpseudocode}
\usepackage[outputdir=build]{minted}
%-- Plotting
%\usepackage{graphicx}

%-- Tables and enumerations
\usepackage{enumerate}
\usepackage{booktabs, multirow}
\usepackage{caption, subcaption}

%-- Bibliography
\usepackage{csquotes}
\usepackage[
  backend=biber,
  style=numeric,
  citestyle=numeric,
  sorting=none
]{biblatex}
\addbibresource{bachelor_thesis.bib}
%-- Numbering
\numberwithin{equation}{section}
\numberwithin{algorithm}{section}
\counterwithin{figure}{section}
\counterwithin{table}{section}


%-- General Formatting
%\usepackage[top=20mm,bottom=20mm,left=25mm,right=25mm]{geometry}
\usepackage{geometry}
\usepackage[english]{babel}
\selectlanguage{english}
\usepackage{fancyhdr}
\usepackage{parskip}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
%\setlength{\parindent}{0pt}
%\setlength{\parskip}{0.5\baselineskip}

\input{assets/diagrams/traingle_helper.tex}


%-----> Document begins here <-----
\begin{document}

% -- Title page

\title{Regularising complex-valued thresholds in numerical integration of loop integrals}
\author{Cedric Sigrist}
\date{\today}
\maketitle

\clearpage

\begin{abstract}
    TODO
\end{abstract}
\clearpage

% -- Table of contents
\setcounter{tocdepth}{2}
\tableofcontents

\clearpage

\section{Introduction}
Perturbative quantum field theory (QFT) is a framework for describing the
interactions between elementary particles (quarks, leptons, gluons, etc.) in
the Standard Model (SM) of particle physics. It is essential for describing
cross-sections, decay rates, and other physical properties of particles and
interactions, that can be measured experimentally.

As experimental accuracy improves, it is increasingly important to compute
accurate higher order contributions of these expansions.

The non-trivial contribution of higher order corrections is often dominated by
loop integrals, which are increasingly difficult to compute with existing
analytical methods like integration by parts (IBP) or differential equation
systems for master integrals.

Because of this, the numerical evaluation of loop integrals has become an
active area of research in recent years. There are many different methods
available including sector decomposition implemented in
\texttt{pySecDec}~\cite{borowka_pysecdec_2018}.

Performing the integral in momentum space has the advantage easier physical
interpretation of the integrand. Certain observables can be computed directly
from the momentum space representation of the integral.

Contour deformation~\cite{capatti_numerical_2020} is a method, where the
integral is performed in momentum space. It is a technique which regularizes
integrable singularities in the integration domain by deforming the integration
contour in the complex plain. In this deformation one must be careful not to
introduce additional residues by crossing over other poles, which do not lie in
the original integration domain.

In this work, I will focus however on threshold
subtraction~\cite{kermanschah_numerical_2022}, which does not require contour
deformation. In threshold subtraction, singularities are isolated and replaced
by a locally defined counterterm that reproduces their behavior exactly at the
singular point. By subtracting this counterterm, the combined integrand remains
finite everywhere in the integration domain and can therefore be integrated via
Monte Carlo integration. Because the singularities are integrable, the
counterterm itself can be integrated analytically by choosing the
parametrization and exact form of the counterterm, such that the counterterm
itself is analytically integrable.

Existing applications, however, predominantly focus on integrals with real
internal masses. In settings involving unstable particles, complex masses are
unavoidable, and their presence modifies the location and character of the
singularities. Whether the threshold subtraction method remains stable and
reliable in this broader context is not a trivial question.

In this work, I investigate the scalar triangle integral with complex internal
masses as a controlled environment in which to test this extension. The scalar
triangle is sufficiently simple to allow for a transparent analysis, yet it
retains essential features introduced by complex masses. Demonstrating that
threshold subtraction can be applied successfully in this setting represents a
step toward its use in realistic multi-loop computations formulated within
complex-mass schemes.

\textbf{TODO:} short intro to complex mass scheme.

In this thesis, I will first derive the Cross Free Family (CFF) representation
of the triangle integral, first algebraically, and then in a newer more
Diagrammatic way due to~\cite{capatti_derivation_2023}. This representation is
suited for threshold subtraction. Following this derivation I will define the
counterterm used in the threshold subtraction. First for a single
sub-expression, called E-surface, and then for all of the E-surfaces of the
integral. With said counterterms defined, I will define the final
threshold-subtracted integral, which will be numerically integrated using
Monte Carlo integration. The numerical stability of this integral is then examined with a few selected examples. First I will look at the equal mass case, with small widths. Then I will look at the equal mass case with no width, exploring what happens as E-surfaces come into play. Finally I will look at kinematics showcasing anomalous thresholds and try to interpret the results using the geometry of the E-surfaces

\section{Scalar Triangle Integral}
I consider the scalar Triangle integral, restricted to complex masses with
$\Re(m_i^2) > 0$ and $\Im(m_i^2) \leq 0$.
\begin{figure}[H]
    \centering
    \input{assets/diagrams/triangle.tex}
    \caption{Feynman diagram of the scalar Triangle integral}\label{fig:triangle_feynman}
\end{figure}
The Feynman diagram in Figure~\ref{fig:triangle_feynman} produces equation~\eqref{eq:triangle_integral}.
\begin{equation}
    I = \int \frac{\dd[4]{k}}{{(2\pi)}^4} \frac{i}{D_1 \, D_2 \, D_3} \label{eq:triangle_integral}
\end{equation}
with
\begin{equation}
    D_i = {(\vb{k}-\vb{q}_i)}^2-{\qty(m_i-i\varepsilon)}^2 = {(\vb{k}-\vb{q}_i)}^2-m_i^2 + i \varepsilon  \label{eq:denom}
\end{equation}
Notice that the feynman causal prescription $-i\varepsilon$ is included in the definition of the denominator. In this thesis, I will sometimes also write the causal prescription implicitly in the masses, i.e. $m_i \to m_i - i\varepsilon$, as it shortens some of the calculations.

The momenta $\vb{q_i}$ are defined as
\begin{align}
    \vb{q}_1 & = \vb{p_1}  \\
    \vb{q}_2 & = \vb{0}    \\
    \vb{q}_3 & = -\vb{p_2}
\end{align}

\subsection{Integration of the Loop Energy}
The structure of the singularities of the triangle
integral~\eqref{eq:triangle_integral} intricate, and the singularities are
present even for large momenta $\vb{k}^\mu \to \infty$. This can be illustrated
by considering eq~\eqref{eq:triangle_integral} in one spacial dimension. The
integrand can the be visualized for all values of $(\vb{k}^0, \vb{k^1}) \in
    \real^2$, as shown in Figure~\ref{fig:1d_example}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/integrand_1D_example.png}
    \caption{Integrand of the scalar triangle integral in one dimension}\label{fig:1d_example}
    Visualization of the absolute value of the integrand of the scalar triangle integral in one spacial dimension.
    With the horizontal axis representing the $k^0$ variable and the vertical axis representing the $k^1$ variable.
    The configuration in this plot is $m_i = \SI{1}{\keV}$, $\vb{p_1} = (2, 1) \, \si{\keV}$ and $\vb{p_2} = (2, -1) \, \si{\keV}$
\end{figure}

We can however already notice, that the number of poles in the $\vb{k}^0$
variable seem to be independent of $\vb{k}^1$, this already suggests. We will
now take a closer look at the poles in the $\vb{k}^0$ variable to then
integrate along it analytically. This does not only have the huge benefit of
simplifying the singularity structure greatly, allowing for the use of
threshold subtraction, it also removes a dimension from the integration domain,
improving performance.

There are many ways to perform the loop energy integration in
eq.~\eqref{eq:triangle_integral}. Following the steps
in~\cite{catani_loops_2008} to rederive the Loop Tree Duality (LTD)
representation by integrating over the energy and then algebraically
manipulating the resulting expression to get a result in the Cross Free Family
(CFF) representation derived in~\cite{capatti_exposing_2023}.

I will perform the $k^0$ integration with Cauchy's theorem. For this we need to
consider the poles of the integrand from Eq.~\eqref{eq:triangle_integral} in
$k^0$. These are given by
\begin{equation}
    k^0 = q_i^0 \pm \qty(\sqrt{{\qty(\va{k}-\va{q}_i)}^2+m_i^2} - i\varepsilon) = q_i^0 \pm E_i
\end{equation}
with
\begin{equation}
    E_i = \sqrt{{\qty(\va{k}-\va{q}_i)}^2+m_i^2} - i\varepsilon
\end{equation}
Closing the contour around the poles corresponding to the principal square roots leads to the contour shown in Figure~\ref{fig:poles}
\begin{figure}[H]
    \centering
    \input{assets/diagrams/poles.tex}
    \caption{Poles of the denominator}\label{fig:poles}
\end{figure}

We can now apply Cauchy's theorem to perform the $k^0$ integral.
\begin{equation}
    I = \int \frac{\dd[3]{k}}{{(2\pi)}^4} 2\pi i \sum_{i= 1}^{3} \On{Res}_{k^0 = q^0_i + E_i}\qty[\frac{i}{D_1D_2D_3}] \label{eq:cauchy}
\end{equation}

Let's compute the residues.
\begin{equation}
    \On{Res}_{k^0 = q^0_i + E_i}\qty[\frac{i}{D_1D_2D_3}] = {\qty[\frac{i}{D_i'}\prod_{i \neq j} \frac{1}{D_j}]}_{k^0=q^0_i + E_i}= \frac{i}{2E_i} \prod_{i\neq j} \eval{\frac{1}{D_j}}_{k^0=q^0_i+E_i} \label{eq:residue}
\end{equation}

\newcommand{\ELIPT}[2]{\eta_{#1#2}^{++}}
\newcommand{\HYPER}[2]{\eta_{#1#2}^{+-}}

We can also introduce $\ELIPT{i}{j}$ called E-Surface and $\HYPER{i}{j}$ called
H-Surface.

\begin{align}
    \eval{D_j}_{k^0=E_i} & = {\qty(q^0_i+E_i-q^0_j)}^2 - \overbrace{{\qty(\va{k}-\va{q}_j)}^2+m_j^2}^{E_j^2}                                                              \\
                         & = E_i^2+{q_i^0}^2+{q_j^0}^2-2q_i^0q_j^0+2q_i^0E_i - 2q_j^0E_i-E_j^2                                                                            \\
                         & = \underbrace{\left(E_i+E_j+q_i^0-q_j^0\right)}_{\ELIPT{i}{j}}\underbrace{\left(E_i-E_j+q_i^0-q_j^0\right)}_{\HYPER{i}{j}} \label{eq:surfaces}
\end{align}
Inserting the results from Eq.~\eqref{eq:surfaces} and Eq.~\eqref{eq:residue} into Eq.~\eqref{eq:cauchy} we get the Loop Tree duality expression.
\newcommand{\BLTD}[3]{2E_{#1}\ELIPT{#1}{#2}\HYPER{#1}{#2}\ELIPT{#1}{#3}\HYPER{#1}{#3}}
\begin{equation}
    I =  \int \frac{\dd[3]{k}}{{(2\pi)}^3}\qty(\frac{1}{\BLTD{1}{2}{3}}+\frac{1}{\BLTD{2}{1}{3}}+\frac{1}{\BLTD{3}{1}{2}}) \label{eq:ltd}
\end{equation}

While this is a nice expression, it is not yet suited for numerical
integration, since all of the H-Surfaces contain singularities which would make
the procedure numerically unstable. It turns out however that these
singularities are spurious and can be removed by purely algebraic
manipulations, shown in detail in Appendix~\ref{sec:improved_ltd}. The
resulting expression contains only E-Surfaces.

\begin{gather}
    I =  \int \dd[3]{k} \mathcal{I}_{CFF} \\
    \mathcal{I}_{CFF} = \frac{1}{{(4\pi)}^3} \frac{1}{E_1E_2E_3} \qty(
    \frac{1}{\ELIPT{2}{1}\ELIPT{3}{1}}
    + \frac{1}{\ELIPT{1}{2}\ELIPT{1}{3}}
    + \frac{1}{\ELIPT{1}{2}\ELIPT{3}{2}}
    + \frac{1}{\ELIPT{2}{1}\ELIPT{2}{3}}
    + \frac{1}{\ELIPT{1}{3}\ELIPT{2}{3}}
    + \frac{1}{\ELIPT{3}{1}\ELIPT{3}{2}}
    )
    \label{eq:cff}
\end{gather}

\subsection{Cross Free Family}
Equation~\eqref{eq:cff} can also be derived directly using a diagrammatic
approach, derived in~\cite{capatti_exposing_2023}.

It shows, that the CFF representation can be obtained by summing over all
possible acyclic edge orientations of the given graph. In the case of the
triangle, there are six possible edge orientations $S = {\{+,-\}}^3 \setminus
    \{(+,+,+), (-,-,-)\}$.

\begin{align}
    \mathcal{I}_{CFF} & = \frac{1}{{(2\pi)}^3}\frac{1}{\prod_{m=1}^{3} 2i\,E_m} \sum_{\va{\sigma} \in S} \hat{\mathbbm{1}}_{\va{\sigma}}                                                       \\
                      & =\frac{1}{{(4\pi)}^3} \frac{-1}{E_1E_2E_3} \qty[\TriDiag{-}{+}{+} + \TriDiag{+}{-}{+} + \TriDiag{+}{+}{-} + \TriDiag{+}{-}{-} + \TriDiag{-}{+}{-} + \TriDiag{-}{-}{+}]
\end{align}

Note that up to permutations of the indices all of these diagrams are
equivalent. We will therefore consider one diagram, and note that the result is
symmetric under the exchange of the indices. It is shown
in~\cite{capatti_derivation_2023}, how this diagram can be evaluated by
recursively retracting contracting edges.

\begin{equation}
    \TriDiagLabeled{+}{-}{+} \quad = \frac{i}{\tilde{E}_1 + \tilde{E}_2} \frac{i}{\tilde{E}_1 + \tilde{E}_3}
\end{equation}
where $\tilde{E}_1 = E_1 - \sigma_1 q_1^0$.
Thus the sum of the $\tilde{E}_1$ values corresponds exactly to the e-surface $\ELIPT{1}{2}$

\begin{equation}
    \tilde{E}_1 + \tilde{E}_2 = E_1 + E_2 - \sigma_1 q_1^0 - \sigma_2 q_2^0 = \ELIPT{1}{2}
\end{equation}

\begin{equation}
    \TriDiagLabeled{+}{-}{+} = \frac{-1}{\ELIPT{1}{2}\ELIPT{1}{3}}
\end{equation}

\section{E-Surface}
Equation~\eqref{eq:cff} can still contain singularities, which need further
treatment to be integrated numerically. The equation is singular when an
E-Surface $\ELIPT{i}{j}$ is zero. For threshold subtraction to work, we will
need to characterize these singularities. In the case of complex masses, this
characterization needs some extra care. We need to make sure to find the zeros
of the E-Surface in the complex plane, rather than in the real plane.

Let us introduce the following definitions.
\begin{align}
    \va{k'} & = \va{k} - \frac{\va{q}_i}{2}(\va{q}_i+\va{q}_j) \label{eq:k_prime} \\
    \vb{q}  & = \frac{1}{2}\qty(\vb{q}_i-\vb{q}_j) \label{eq:q}
\end{align}
This the E-Surface simplifies to the following form.
\begin{equation}
    \ELIPT{i}{j} =  \sqrt{{(\va{k'}-\va{q})}^2+m_i^2} + \sqrt{{(\va{k'}+\va{q})}^2+m_j^2} + 2q^0 \overset{!}{=} 0\label{eq:e_surface}
\end{equation}

\subsubsection{E-Surface existence condition}\label{sec:e_surface_exist}
Equation~\eqref{eq:e_surface} allows us to find a necessary but not sufficient
condition for the existence of the E-Surface. Considering
equation~\eqref{eq:identity} and remembering that we assume $\Re(m_i^2) > 0$
and $\Re(m_j^2) > 0$ we find that for any solution to exist, the following
identity must hold, because the evaluations of the square roots always have
positive real parts.
\begin{equation}
    \Re(C) = 2 q^0 < 0 \label{eq:e_surface_existence_condition}
\end{equation}
This condition already excludes exactly half of the E-surfaces from having any solutions because
\begin{equation}
    i \leftrightarrow j \implies q \leftrightarrow -q
\end{equation}
This also implies that there exists an ordering of the indices $i$ and $j$ such that the condition~\eqref{eq:e_surface_existence_condition} holds exactly when $i<j$.

To make further progress we will assume that the condition
in~\eqref{eq:e_surface_existence_condition} holds and precede by noticing that
the E-Surface is of the same structure as the following.
\begin{equation}
    \sqrt{A}+\sqrt{B} + C = 0 \label{eq:identity}
\end{equation}
We will now derive a characterization of the solutions of equation~\eqref{eq:identity}.
\begin{align}
    \sqrt{A}+\sqrt{B} + C =                              & 0                        \\
    \implies\quad 2\sqrt{AB}                             & = C^2-A-B                \\
    \implies\quad 4AB                                    & = {(C^2-A-B)}^2          \\
    \implies\quad C^2 - 2(A+B) + {\qty(\frac{A-B}{C})}^2 & = 0 \label{eq:identity2}
\end{align}

\subsubsection{Treatment of extraneous solutions}\label{sec:extraneous_solutions}
The steps taken to derive equation~\eqref{eq:identity2} may introduce
extraneous solutions to the E-Surface equation~\eqref{eq:e_surface}. I propose
and compare two methods to treat these extraneous solutions.
\begin{itemize}
    \item \textbf{Numerical Check Existence Condition:}\\
          Check solutions by inserting and checking if the expression evaluates to $0$.
          This is very easy to implement numerically, but in practice it will
          unfortunately need to rely on floating point precision. It is also necessary to
          perform this check per sample, which in turn means that samples concerning the same E-surface may be excluded / included depending on the solid angle $\hat{\vb{k}}$.

    \item \textbf{Minimum Value Existence Condition:}\\
          Compute the minimum value of $\sqrt{A}+\sqrt{B}+C = 0$ over real valued inputs. If the real part is
          negative, then there exist solutions with $\Re(A)>0$ ans $\Re(B)>0$ and thus
          the derivation of equation~\eqref{eq:identity2} can not introduce extraneous solutions. If the minimum
          value is positive, then extraneous solutions may have been introduced and thus we need to remove them.
          This method may remove valid solutions, but it is guaranteed to not
          introduce extraneous solutions. Valid solutions removed in this way necessarily
          lie in the complex plane and thus may not significantly affect the result.

          To compute the minimum value of the equation~\eqref{eq:e_surface}, we can
          notice that it is convex and solve for $\nabla_{\va{k'}} \ELIPT{i}{j} = 0$,
          which yields
          \begin{equation}
              \va{k'}_{\text{min}} = \frac{m_j-m_i}{m_i+m_j} \va{q}
          \end{equation}
          We can then compute the minimum value of the E-Surface equation~\eqref{eq:e_surface} by evaluating it at this point.
\end{itemize}

\subsubsection{E-surface characterization}
For the characterization of the E-surface we will need a single quadratic
equation in some radial variable $k$. We can do this by rewriting the E-Surface
equation~\eqref{eq:e_surface} using equation~\eqref{eq:identity2}. After some
simplification this yields
%\begin{align*}
%    A-B &= -4\va{k'}\cdot \va{q} + m_i^2 - m_j^2\\
%    A+B &= 2\va{k'}^2 + 2 \va{q}^2 + m_i^2 + m_j^2
%\end{align*}
\begin{equation}
    4{q^0}^2 - 2 \qty(2\va{k'}^2 + 2 \va{q}^2 + m_i^2 + m_j^2) + {\qty(\frac{-4 \va{k'}\cdot \va{q} + m_i^2 - m_j^2}{-2q^0})}^2= 0
\end{equation}
This equation can be further simplified, showing that it is quadratic in $\va{k}'$.
At this point it also makes sense to simplify with the lorentz invariant quantity $\vb{q}^2 = {q^0}^2 - \va{q}^2$.
%\begin{equation}
%    \vb{q}^2-\frac{m_i^2 + m_j^2}{2} - \va{k'}^2 + {\qty(\va{k'}\cdot \frac{\va{q}}{q^0})}^2 - 2 \qty(\frac{m_i^2 - m_j^2}{4q^0}) \qty(\va{k'}\cdot \frac{\va{q}}{q^0}) + {\qty(\frac{m_i^2 - m_j^2}{4q^0})}^2 = 0
%\end{equation}
\begin{equation}
    \va{k'}^2 - {\qty(\va{k'}\cdot\va{v})}^2 - 2 \Delta \qty(\va{k'}\cdot\va{v}) - \vb{q}^2 + \braket{m^2} + \Delta^2 = 0 \label{eq:quad_k_prime}
\end{equation}
with
\begin{equation}
    \va{v} = \frac{\va{q}}{q^0}
    \qquad
    \braket{m^2} = \frac{m_i^2 + m_j^2}{2}
    \qquad
    \Delta = \frac{m_i^2 - m_j^2}{4q^0}
\end{equation}
\subsection{E-surface in hemispherical coordinates}
To perform threshold subtraction we will need to find the roots of
equation~\eqref{eq:quad_k_prime} along a given line $k = k\,\hat{\vb{k}} +
    \va{k_0}$. In this parametrization we have
\begin{equation}
    \va{k'} =  k\,\hat{\vb{k}} + \underbrace{\va{k_0} - \frac{1}{2}(\va{q}_i+\va{q}_j)}_{\va{k'_0}} \label{eq:parametrization}
\end{equation}
The roots of equation~\eqref{eq:quad_k_prime} in the radial variable $k$ in the parametrization~\eqref{eq:parametrization} are given by the following quadratic equation.

\begin{equation}
    \alpha k^2 + \beta k + \gamma = 0 \label{eq:quadratic_k}
\end{equation}
with
\begin{align}
    \alpha & = 1-{\qty(\hat{\vb{k}}\cdot\va{v})}^2                                                                             \\
    \beta  & = 2(\hat{\vb{k}}\cdot\va{k'_0})-2(\hat{\vb{k}}\cdot\va{v})(\va{k'_0}\cdot\va{v})-2\Delta(\hat{\vb{k}}\cdot\va{v}) \\
    \gamma & = \va{k'_0}^2-{\qty(\va{k'_0}\cdot\va{v})}^2-2\Delta(\va{k'_0}\cdot\va{v})-\vb{q}^2+\braket{m^2}+\Delta^2
\end{align}
This quadratic equation can be solved with the standard quadratic formula, and thus always has exactly two complex valued solutions, which we will call $k^*_+$ and $k^*_-$. These solutions need to be checked for validity with one of the proposed methods.

Additional care needs to be taken when the solutions $k^*$ are real, as the
prescription of the solutions is not well defined in this case and will be
relevant in Section~\ref{sec:thresh}. The prescription may be reintroduced to
the factors $\alpha, \beta, \gamma$ via the mass $m_i \to m_i - i\varepsilon$.
By carefully propagating this prescription through the quadratic formula we
will obtain the correct solutions.

\begin{align}
    k^*_{\pm} = \frac{-\beta \pm \sqrt{\beta^2-4\alpha\gamma}}{2\alpha} \pm i\varepsilon
\end{align}

\subsection{Equal-mass case}~\label{sec:equal_mass_case}
It is worthwhile to consider the case where $m_i = m_j = m \in \real$ to build
geometric intuition of the solutions. In this case the quadratic
equation~\eqref{eq:quadratic_k} simplifies, and the geometry of the solutions
is more transparent.

Choosing the parametrization~\eqref{eq:parametrization} with $\va{k'_0} =
    \va{k_0}$ it is possible to simplify equation~\eqref{eq:quadratic_k} to
simplify the quadratic equation into the following.
\begin{equation}
    k^2 = \frac{\vb{q}^2-m^2}{1-{\qty(\hat{\vb{k}} \cdot \va{v})}^2} \label{eq:quadratic_k_simple}
\end{equation}
Considering that if the external momenta are onshell, we find that $\norm{v} < 1$. This ensures that we do not divide be zero, and the sign of the denominator is always positive.
Thus we can see, that real solutions for $k$ only exist if $\vb{q}^2-m^2 > 0$. In this case equation~\eqref{eq:quadratic_k_simple} defines a prolate spheroid. This is the shape of the E-surface for equal-mass particles.
In Figure~\ref{fig:e_surf_example} we see an example of an E-surface in the equal mass case.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/e_surf_example}
    \caption{Example of an E-surface in the equal mass case}\label{fig:e_surf_example}
    Example of an E-surface in the equal mass case with $\vb{q} = (-2,0,0,-1)$ and $m = 1$.
    The major axis is shown in red, the length of which was obtained from the quadratic equation~\eqref{eq:quadratic_k_simple}, the direction of the major axis was obtained as $\va{v}/\norm{\va{v}}$.
    The E-surface itself is shown in cyan and was computed via equation~\eqref{eq:e_surface} and the python visualization tool \texttt{Pyvista}.
\end{figure}

\section{Threshold Subtraction for one E-Surface}\label{sec:thresh}
Threshold singularities appear whenever a loop momentum $\va{k}$ is on an
E-surface. These integrable singularities make numerical integration of the
integrand impossible, if not treated appropriately.

The idea of threshold subtraction is straightforward: isolate the pole
generated by a single E-surface and subtract a locally defined counterterm that
reproduces its behavior exactly at the singular point. This ensures that the
combined integrand remains finite everywhere in the integration domain. In a
well chosen parametrization, it suffices to integrate along a a single
dimension to integrate over the pole. This integration can be performed
analytically, or with some other stable procedure, thus eliminating the
singularity entirely.

In resent approaches, only singularities lying exactly in the integration
domain are considered for threshold
subtraction~\cite{kermanschah_numerical_2022,kermanschah_numerical_2024,capatti_loop_2019}.
In this thesis I extend this idea to singularities that are not exactly in the
integration domain, but instead are shifted to the complex plane. While not
strictly necessary for the convergence of the integrand, this extension allows
for a more general treatment of singularities and improves numerical stability
in cases where the singularities are very close to the integration domain.

\subsection{Subtraction of a single E-Surface}
To remove the threshold singularity corresponding to an E-surface, we will
define a local counterterm for an integrand of the form
\begin{equation}
    \mathcal{I} = \frac{f_{ij}(\va{k})}{\ELIPT{i}{j}}
\end{equation}
where $f_{ij}$ is the coefficient of $\ELIPT{i}{j}$, i.e., the factor that remains after factoring out $\ELIPT{i}{j}$ from the integrand.
The zeros of $\ELIPT{i}{j}$ along the radial direction can then be found with Eq.~\eqref{eq:quadratic_k}.

Denote the set of solutions, checked for validity with one of the methods
described in Section~\ref{sec:e_surface_exist}, as $\mathcal{K}_{ij}$, it
contains at most two solutions.

The singular behavior of the integrand can fully be captured by the first-order
taylor expansion in $\ELIPT{i}{j}$ around a pole, located at $k^* \in
    \mathcal{K}_{ij}$.
\begin{equation}
    \ELIPT{i}{j} = 0 + (k-k^*) \underbrace{\eval{\pdv{k} \ELIPT{i}{j}}_{\va{k}=\va{k^*}}}_{\eta'_{ij}} + \order{{(k-k^*)}^2}
\end{equation}
We can now define a counterterm that will cancel the singularity at $k^*$
\begin{equation}
    \on{CT}_{ij, k^*}(k) = \chi (\va{k}) \frac{f(\va{k^*})}{(k-k^*) \, \eta'_{ij}}
\end{equation}
where $\chi (\va{k})$ is an arbitrary mask, that is smooth at $\chi (\va{k}^*) = 1$ and vanishing as $\abs{k-k^*} \to \infty$
The partial derivative along the radial variable $k$ is straightforward to compute explicitly.
\begin{equation}
    \eta'_{ij} = \eval{\pdv{k} \ELIPT{i}{j}}_{\va{k}=k^* \hat{\vb{k}} } = {\qty[\frac{1}{E_i}(\va{k}-\va{q}_i)\cdot \hat{\vb{k}} + \frac{1}{E_j}(\va{k}-\va{q}_j)\cdot \hat{\vb{k}} ]}_{\va{k} = k^* \hat{\vb{k}}}
\end{equation}

By construction, subtracting the counterterm $\on{CT}_{ij}(k^*)$ will remove
the singularity at $k^*$ from the integrand.

\subsection{Radially integrating the counterterm}
The choice of the mask $\chi$ determines many properties of the counterterm. We
can write the radial integral in hemispherical coordinates centered at
$\va{k_0}$
\begin{equation}
    I_{\on{CT}_{ij}} =  \int_{-\infty}^{\infty} \dd{k} {k}^2 \on{CT}_{ij, k^*} (\vec{k})
\end{equation}
with
\begin{equation}
    \va{k} = k \hat{\vb{k}} + \va{k_0}
\end{equation}

Several useful observations can be made on the choice of $\chi$.
\begin{itemize}
    \item By choosing $\chi = \frac{{k^*\pm}^2}{k^2}$, the Jacobian factor $k^2$ is
          canceled, leaving a simple $\frac{1}{k-k^*}$ integrand for the radial integral.
          Care must be taken when canceling the Jacobian factor this way. The
          parametrization of the subtracted integrand must match the parametrization of
          the counterterm, or other additional steps must be taken, to not introduce
          additional singularities into the integrand. In this thesis we will only
          consider the case where the counterterm is parametrized in the same way as the
          integrand.
    \item If $\chi = \frac{{k^*}^2}{k^2} f(k)$ where $f$ is an even function, the real
          part of the integration vanishes, simplifying the computation.
\end{itemize}

For our purposes we choose a mask that is only nonzero in a finite region and
cancels the Jacobian factor.
\begin{equation}
    \chi{\va{k}} = \begin{cases}
        \frac{{k^*}^2}{k^2} & \abs{k\Re(k)-\mu} < \lambda \\
        0                   & \text{else}
    \end{cases}
\end{equation}
With the real valued hyperparameter $\mu$ and $\lambda$. For a succesful subtraction we need to make sure, that the pole of the counterterm is inside the mask, i.e. $\abs{\Re(k^*)-\mu} < \lambda$.
With this choice the radial integral becomes particularly simple
\begin{equation}
    \int \dd{k} I_{\on{CT}}(k^*) = \int_{\mu - \lambda}^{\mu + \lambda} \dd{k} \frac{1}{k-k^*} = \ln(\frac{\mu + \lambda-k^*}{\mu-\lambda-k^*})
\end{equation}
In the special case, where $\mu = \Re k^*$, the real part vanishes due to symmetry around $\Re k^*$, leaving
\begin{equation}
    \int \dd{k} =  -i \qty(\pi + 2\arctan(\frac{\Im k^*}{\lambda}))
\end{equation}
This result is consistent with the result derived in~\cite{capatti_exposing_2023} as $\Im k^* \to 0$
\section{Multiple E-Surfaces}
When starting to consider multiple E-surfaces we can simply add the
counterterms for each E-surface separately.

Without loss of generality we can reorder $\vb{q}_i$ such that $\vb{q}_1 <
    \vb{q}_2 < \vb{q}_3$. Thus the existence condition derived in
equation~\eqref{eq:e_surface_existence_condition} is fulfilled for the
E-Surfaces $\ELIPT{i}{j}$ with $i<j$. Each of these may require it's own
counterterm.

Consider $\ELIPT{1}{2}$ as an example, to compute the factor $f_{12}$ we need
to collect all factors containing $1/\ELIPT{1}{2}$ from
equation~\eqref{eq:cff}.
\begin{equation}
    \ELIPT{1}{2} \frac{1}{{(4\pi)}^3}\frac{1}{E_1E_2E_3} \qty(\frac{1}{\ELIPT{1}{3}}+\frac{1}{\ELIPT{3}{2}}) = \ELIPT{1}{2} \, f(\va{k})
\end{equation}
The counterterm removing the pole at either $k^*\in \mathcal{K}_{12}$ is therefore given by
\begin{equation}
    \on{CT}_{12}(k^*) = \chi(k-k^*) \, f(\va{k}) \,\frac{1}{\eta'_{12}} \,  \frac{1}{k-k^*}
\end{equation}
The same procedure applies to $\ELIPT{2}{3}$ and $\ELIPT{1}{3}$

\subsection{Definition of the full integral}
For the numerical final numerical integration it is useful to combine the
everything into a single integral. This approach improves compiler optimization
of the integrand and may also improve numerical stability by better capturing
correlations and cancellations between the different parts.

There are many ways to add the radially integrated counterterm back into an
integrand over $k \in \real^3$. For now we will consider a general mask $g(k)$,
which is normalized along the radial variable $k$.
\begin{equation}
    \int \dd{k} k^2 g(k) = 1
\end{equation}

By introducing factors $\mathbf{a}, \mathbf{b}, \mathbf{c} \in \{0,1\}$ to
scale the original integrand, the counterterm and the integrated counterterm we
can then also use a single implementation to evaluate any of the relevant
integrands, by setting the appropriate factors to zero.

\begin{equation}
    I =
    \int \dd[2]{\hat{\vb{k}}} \int \dd{k} k^2 \qty[ \mathbf{a}\;\mathcal{I}_{CFF} +
    \sum_{i<j} \sum_{k^* \in \mathcal{K}_{ij}}
    \qty( -\mathbf{b}\;\text{CT}_{ij}(k^*) + \mathbf{c}\;g(k)\,I_{\on{CT}_{ij}}(k^*))] \label{eq:integrand}
\end{equation}

We will consider two different functions $g(k)$
\begin{equation}
    g(k) = \Theta(\lambda - \abs{\Re(k)-\mu}) \frac{3}{(\mu+\lambda)^3 - (\mu-\lambda)^3}
\end{equation}

\begin{equation}
    g(k) = \exp(-\frac{(\Re(k)-\mu)^2}{\lambda^2}) \frac{1}{\sqrt{\pi} \lambda (\mu^2 + \frac{\lambda^2}{2})}
\end{equation}

\subsection{Local cancellation in Counterterm}
\textbf{TODO:} Explain what might be a problem, and why it is not.

\section{Numerical implementation}
The numerical integration is performed with the Python API of the
\texttt{Symbolica} library \texttt{Symbolica} supports compilation of symbolic
expressions into optimized assembly code for fast evaluation. It also provides
an efficient implementation of the \texttt{VEGAS} Monte Carlo integration
algorithm, which is well suited for this problem.

\subsection{Parametrization}
\texttt{Symbolica} provides efficient sampling in $N$-dimensional hypercubes.
There are many reasonable choices to map from the unit hypercube to hemispherical coordinates. I choose the following mapping from unit hypercubes to the relevant parametrizations with their respective Jacobians $J$.

\textbf{Unit Hemisphere}

\begin{equation}
    \vb{\hat{k}}(v, w) =
    \begin{pmatrix}
        \sin(\phi) \cos(2 \pi w) \\
        \sin(\phi) \sin(2 \pi w) \\
        \cos(\phi)
    \end{pmatrix}
\end{equation}
with
\begin{equation}
    \cos(\phi) = 1 - 2 v\qquad
    \sin(\phi) = \sqrt{1-\cos^2(\phi)}\qquad
    J_{\vb{\hat{k}}} = 2 \pi
\end{equation}

\textbf{Hemispherical coordinates}

\begin{equation}
    \va{k}(u, v, w) = r \vb{\hat{k}}(v, w)
\end{equation}

\begin{equation}
    \tilde{u} = 2\,u-1 \qquad
    r = \tilde{u} - \frac{1}{\tilde{u}} \qquad
    J = \frac{r^2 \, J_{\vb{\hat{k}}}}{{(1-\tilde{u})}^2}
\end{equation}

\subsection{Reference}
The \textit{OneLOop} package~\cite{hameren_oneloop_2011} provides
implementation for scalar loop integrals with up to 4 legs. I will use the open
source package
\textit{OneLOopBridge}\footnote{\url{https://github.com/SecretGmG/OneLOopBridge}}
that was written in conjunction to this thesis to compute the reference values
for the integrals.\textit{OneLOopBridge} provides Python and Rust bindings for
the \textit{OneLOop} package, which is written in fortran. A more detailed
description of the usage of \textit{OneLOopBridge} can be found in
Appendix~\ref{sec:oneloopbridge}.

\section{Small width}\label{sec:regularizing_masses}
It is possible to regularize the integral by adding a small imaginary part to
the masses. In this example I show the effect of this regularization on the
numerical stability of the integral. As the regularization becomes smaller the
threshold subtraction becomes necessary to ensure numerical stability of the
integral, even for small \textit{finite} widths.

The external momenta in this example are chosen, such that they are aligned
with the $z$-axis and in the COM-system. The masses in this example are always
chosen to be equal $m_i = m$.

\begin{align*}
    \vb{p_1}^2 = \SI{1}{\GeV^2} \qquad \vb{p_2}^2 = \SI{3}{\GeV^2} \qquad {(\vb{p_1}+\vb{p_2})}^2 = \SI{8}{\GeV^2}\qquad \Re(m) = \SI{0.2}{\GeV}
\end{align*}

In this example all of the three possible E-surfaces exist, this can be easily
checked by applying the minimum value existence condition derived in
Section~\ref{sec:extraneous_solutions}.

This example will be used to compare the convergence behavior of different
hyperparameter, as the width, which regularizes the integral gets smaller and
thus the threshold subtraction becomes necessary. The following setups will be
compared:

\begin{itemize}
    \item \textbf{No subtraction}
    \item \textbf{Centered subtraction} Threshold subtraction where the effective region of the subtraction is centered around the origin, with a radius of $\lambda = \SI{2.5}{\GeV}$. The mask for the integrated counterterm is similarly a sphere with the same radius.
    \item \textbf{Sliver subtraction} Threshold subtraction where the effective region of the subtraction is a sliver with a half width of $\lambda = \SI{1}{\GeV}$. Similarly the mask for the integrated counterterm is a sliver with the same half width.
\end{itemize}

The threshold subtraction for the centered and uncentered cases are shown in
Figure~\ref{fig:threshold subtraction_centered} and Figure~\ref{fig:threshold
    subtraction_uncentered} respectively. On the lower half of the plots, where the
integrand is shown along the $z$-axis it can be seen qualitatively that the
threshold subtraction successfully removes the poles and flattens the
integrand. We may also notice, that the sliver threshold subtraction produces
more discontinuities.

Subtracting a sliver does however have the advantage of being more robust with
respect to the choice of the hyperparameter $\lambda$, which is the half width
of the sliver, as the subtraction region will \textit{always} contain the pole.
Whereas subtracting a centered region will only contain the pole if the
hyperparameter is large enough.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/small_width/centered_subtraction.png}
    \caption{Centered Threshold Subtraction}\label{fig:threshold subtraction_uncentered}
    Visualization of the threshold subtraction, with complex mass $m = (0.2-0.01 \mathit{i})\si{\GeV}$, using the
    The unsubtracted integrand, the counterterm and the subtracted integrand are shown in the $xz$-plane. The colormap is such the brightness corresponds to the absolute value of the function and the hue corresponds to the phase, with cyan corresponding to positive values and red corresponding to negative values.
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/small_width/uncentered_subtraction.png}
    \caption{Sliver Threshold Subtraction}\label{fig:threshold subtraction_centered}
    Visualization of the threshold subtraction, with complex mass $m = (0.2-0.01 \mathit{i})\si{\GeV}$.
    The unsubtracted integrand, the counterterm and the subtracted integrand are shown in the $xz$-plane. The colormap is such the brightness corresponds to the absolute value of the function and the hue corresponds to the phase, with cyan corresponding to positive values and red corresponding to negative values.
\end{figure}

The integration is performed using the complex mass regularization for
$-\Im(m)$ approaching zero. This coefficient is computed separately for the
real and imaginary parts of the integration. The result of the numerical
integration is shown in Figure~\ref{fig:small_width_integration}. It can be
seen, that both the sliver and centered subtraction converge well on the
correct result, even as the width gets smaller.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/small_width/integration_centered.png}
        \caption{Integration for centered subtraction}
        Integration for the centered subtraction for a range of decay widths.
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/small_width/integration_uncentered.png}
        \caption{Integration for uncentered subtraction}
        Integration for the sliver subtraction for a range of decay widths.
    \end{subfigure}
    \caption{Comparison of subtraction regions across a range decay widths}\label{fig:small_width_integration}
\end{figure}

We can measure the convergence of the monte carlo integration using the
coefficient of variation, defined as the standard deviation divided by the
mean.
\begin{equation}
    \on{CV} = \frac{\sigma}{\mu}
\end{equation}
The coefficient of variation is shown in Figure~\ref{fig:small_width_cv}. It can be seen, that both subtraction methods have a great impact on the convergence of the integral. The coefficient of variation of the unsubtracted method increases exponentially as the width gets smaller, while the coefficient of variation of the subtracted method is less sensitive to the width. It is also interesting to note, that the centered subtraction has a lower coefficient of variation than the sliver subtraction. This difference may be caused by fact that the sliver subtraction produces more discontinuities, which may make it harder for the VEGAS sampler to learn the integrand.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/small_width/cv.png}
    \caption{Coefficient of variation for a range of masses}\label{fig:small_width_cv}
    Coefficient of variation for a range of masses comparing the per-sample and global E-surface existence conditions.
\end{figure}

\section{Threshold masses}

We will now take a closer look at what happens in configurations with real
masses, where imaginary solutions to the E-surface
equation~\eqref{eq:e_surface} exist. We will check if subtracting the imaginary
solutions in these cases improve numerical stability especially for
configurations very close to thresholds where E-surfaces come into existence.

Using the same kinematic configuration as in
Section~\ref{sec:regularizing_masses} and equal internal masses $m_i = m$, we
will vary the mass to check numerical stability of the integral as E-surfaces
cross the boundary of having real to complex solutions.

\begin{align*}
    \vb{p_1}^2 = \SI{1}{\GeV^2} \qquad \vb{p_2} 2 = \SI{3}{\GeV^2} \qquad {(\vb{p_1}+\vb{p_2})}^2 = \SI{8}{\GeV^2} \qquad \Im(m) = 0
\end{align*}

Using the E-surface existence condition for the equal mass case derived in
Section~\ref{sec:equal_mass_case} we can compute the values of the masses where
the E-surface equation~\eqref{eq:e_surface} goes from having real to complex
solutions. We will call these masses threshold masses. For this example they
are
\begin{equation}
    m^2 = \SI{0.25}{\GeV} \qquad m^2 = \SI{0.75}{\GeV} \qquad  m^2 = \SI{2}{\GeV}
\end{equation}

Plotting the integral over a range including all of these threshold masses
shown in Figure~\ref{fig:threshold_masses_integral} we see that, at least
superficially, both methods of subtracting E-surfaces converge well on the
correct result. We can also note that for masses larger than the largest
threshold mass, the imaginary part of the integrand is equal to zero. This is
expected, because in this case no singularities exist in the real valued
integrand, that could introduce any imaginary part.

It is important to note however, that for the per-sample method, the imaginary
part of the integrand is not equal to zero, even in this region, because
complex solutions of the E-surface equation get subtracted. As we can see, the
per-sample method still converges well in this case, showing that the imaginary
parts of the counterterm and integrated counterterm cancel themselves out
exactly.

The result of the numerical integration is shown in
Figure~\ref{fig:threshold_masses_integral}. It can be seen, that both methods
converge well on the correct result.
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/threshold_masses/global_check.png}
        \caption{With Minimum Value Existence Condition}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/threshold_masses/per_sample_check.png}
        \caption{without Minimum Value Existence Condition}
    \end{subfigure}
    \caption{Integration Result with different E-surface Existence Conditions}\label{fig:threshold_masses_integral}
\end{figure}

It is more interesting to look at the coefficient of variation for the
different methods. This is shown in Figure~\ref{fig:threshold_masses_cv}. It is
to be expected, that for masses, smaller then the smallest threshold mass $m^2
    < \SI{0.25}{\GeV}$

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/threshold_masses/cv.png}
    \caption{Coefficient of variation for a range of masses}\label{fig:threshold_masses_cv}
    Coefficient of variation for a range of masses comparing the per-sample and global E-surface existence conditions.
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/threshold_masses/cv_zoomed.png}
    \caption{Coefficient of variation for a range of masses}\label{fig:threshold_masses_cv_zoomed}
    Coefficient of variation for a range of masses comparing the per-sample and global E-surface existence conditions.
\end{figure}

\section{Anomalous thresholds}
\textbf{TODO:} Explain why they are interesting, explain why and how to choose the integration center, as i did, show numerical stability, compute the integral exactly on the threshold~\cite{passarino_peaks_2018}

In this example we consider a configuration with fixed masses $m_1 = m_2 =
    m_\text{Top}, m_3 = m_\text{Bottom}$ and fixed external momenta $\vb{p}_1^2$
and ${(\vb{p}_1+\vb{p}_2)}^2$, varying $\vb{p_2}^2$. This configuration is
discussed in~\cite{passarino_peaks_2018}, which allows us to compare the
results.

To take full advantage of the local cancellations, it is important to choose
the integration center such that it is inside all of the E-surfaces that
intersect.

\section{Generalization to higher loop count}
\textbf{TODO:} Explain what might be a problem, and what might not be. Showcase how newtons method converges.

\section{Conclusion}
\textbf{TODO:} Write conclusion

\printbibliography

\input{appendix.tex}

\end{document}